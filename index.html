<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
	<head>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<meta name="Author" content="Xiaoling Zhou, 周晓玲" />
		<meta name="description" content="Xiaoling Zhou, Homepage, 周晓玲,北京大学,软件与微电子学院,深度学习,自然语言处理,机器学习">
		<meta name="keywords" content="Xiaoling Zhou, 周晓玲,北京大学,软件与微电子学院,深度学习,自然语言处理,机器学习">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<link rel="stylesheet" href="my.css" type="text/css" />
		<title>Xiaoling Zhou</title>



		<style type="text/css">
			div.noshow { display: none;}
		</style>
		<script type="text/javascript">
			<!--
			function toggleInfo(articleid,info) {

				var entry = document.getElementById(articleid);
				var abs = document.getElementById('abs_'+articleid);
				var rev = document.getElementById('rev_'+articleid);
				var bib = document.getElementById('bib_'+articleid);

				if (abs && info == 'abstract') {
					if(abs.className.indexOf('abstract') != -1) {
						abs.className.indexOf('noshow') == -1?abs.className = 'abstract noshow':abs.className = 'abstract';
					}
				} else if (rev && info == 'review') {
					if(rev.className.indexOf('review') != -1) {
						rev.className.indexOf('noshow') == -1?rev.className = 'review noshow':rev.className = 'review';
					}
				} else if (bib && info == 'bibtex') {
					if(bib.className.indexOf('bibtex') != -1) {
						bib.className.indexOf('noshow') == -1?bib.className = 'bibtex noshow':bib.className = 'bibtex';
					}
				} else {
					return;
				}

				// check if one or the other is available
				var revshow = false;
				var absshow = false;
				var bibshow = false;
				(abs && abs.className.indexOf('noshow') == -1)? absshow = true: absshow = false;
				(rev && rev.className.indexOf('noshow') == -1)? revshow = true: revshow = false;
				(bib && bib.className == 'bibtex')? bibshow = true: bibshow = false;

				// highlight original entry
				if(entry) {
					if (revshow || absshow || bibshow) {
						entry.className = 'entry highlight show';
					} else {
						entry.className = 'entry show';
					}
				}

				// When there's a combination of abstract/review/bibtex showing, need to add class for correct styling
				if(absshow) {
					(revshow||bibshow)?abs.className = 'abstract nextshow':abs.className = 'abstract';
				}
				if (revshow) {
					bibshow?rev.className = 'review nextshow': rev.className = 'review';
				}

			}

			function showAll(){
				// first close all abstracts, reviews, etc.
				closeAllInfo();

				for (var i = 0; i < numEntries; i++){
					entryRows[i].className = 'entry show';
				}
			}

			function closeAllInfo(){
				for (var i=0; i < numInfo; i++){
					if (infoRows[i].className.indexOf('noshow') ==-1) {
						infoRows[i].className = infoRows[i].className + ' noshow';
					}
				}
			}


			-->
		</script>





	</head>	
	<body>
		<div id="pagecell1">
			<!--pagecell1-->
			<div id="top">
				
				<h1><a href="index.html">周晓玲</a></h1> 博士在读，北京大学，软件与微电子学院，人工智能
<!--				<h1><a href="index.html">周晓玲</a></h1> 博士在读，北京大学，软件与微电子学院，电子信息（关键基础软件）-->

				<div id="top-right">
					 <a href="index.html"> 首页 </a>  | <a href="#publications">出版物</a> | <a href="#awards">所获奖励</a> | <a href="#honors">所获荣誉</a>  | <a href="#projects"> 科研项目 </a>  | <a href="#acs"> 学术服务 </a>| <a href="en.html"> English </a>
				</div>
			</div>
			
			<div id="left">
				<img src="./picture/xlzhou.jpg" alt="" /><!--width="285" height="325" /-->
				<p>&nbsp;</p>
				<div>
					<h2>链接</h2>
						<p ><a href="mailto:xiaolingzhou@stu.pku.edu.cn" target="_blank"><i class="icon-share-alternitive"></i> Email</a></p>
						<!-- <p ><a href="http://github.com/xiaolingzhou1998" target="_blank"><i class="icon-github"></i> Github</a></p> -->
					    <!-- <p><a href="" target="_blank"><i class="icon-android"></i> QQ (349386795)</a></p> -->
					    <p ><a href="https://scholar.google.com/citations?user=RqBrDxcAAAAJ&hl=zh-CN&oi=ao" target="_blank"><i class="icon-chrome"></i> Google Scholar</a></p>
<!--						<p ><a href="https://www.zhihu.com/people/xpqiu" target="_blank"><i class="icon-zhihu-square"></i> 知乎</a></p>-->
						<h2>联系方式</h2>
						<p class="list1" >北京市海淀区颐和园路5号北京大学软件与微电子学院</p>

					</div>
			</div>


			<div id="content">

				<div class="feature">
					<h2>个人简介</h2>
					<div class="story">
						<p style="text-align: justify"> &emsp;您好！我是周晓玲，目前就读于北京大学软件与微电子学院，攻读博士学位（2023年9月至今）。 我的导师是张世坤教授和<a href="https://se.pku.edu.cn/kcl/weiye/"><strong>叶蔚</strong></a>教授。 我的研究兴趣包括特征学习、对抗训练、元学习、不平衡学习和因果分析等领域；目前发表和在投论文10余篇。</p>

						<!-- <p>&emsp;我曾参加多项学科竞赛并获奖。包括美国大学生数学建模竞赛一等奖等5项国家级奖项，天津市大学生物理竞赛特等奖等10多项省级奖项；
							我主持完成一项国家级大学生创新项目，申请一项软件著作权一项实用新型专利和一项发明专利。</p> -->

						<p style="text-align: justify">	&emsp;如需了解更多信息，欢迎通过我的<a href="mailto:xiaolingzhou@stu.pku.edu.cn">电子邮件</a>与我联系:)</p>
					</div>

					<!-- <h2>研究方向</h2>
						<p>深度学习、自然语言处理、样本赋权策略、微扰对抗训练、因果分析。</p> -->

					<h2>更新信息</h2>
						<ol>
							<div style="height:130px;overflow:auto;">
									<table>
										<col width="100px">
										<!-- <tr>
											<td><b>Jan 2023:</b></td>
											<td>参加并通过北京大学软件与微电子学院博士考核！</td>
										</tr> -->
										<tr>
											<td><b>2023/09:</b></td>
											<td>论文《Investigating the Sample Weighting Mechanism Using an Interpretable Weighting Framework》被IEEE Transactions on Knowledge and Data Engineering （CCF A）期刊接收。</td>
										</tr>
										
										
										<tr>
											<td><b>2023/06:</b></td>
											<td>荣获天津大学优秀毕业生。</td>
										</tr>
										<tr>
											<td><b>2023/06:</b></td>
											<td>荣获天津大学优秀硕士学位论文。</td>
										</tr>
										<tr>
											<td><b>2023/06:</b></td>
											<td>论文《Which Samples Should be Learned First, Easy or Hard?》发表在 IEEE Transactions on Neural Networks and Learning Systems (TNNLS) 期刊（CCF-B）。</td>
										</tr>
										<tr>
											<td><b>2022/11:</b></td>
											<td>论文《Combining Adversaries with Anti-adversaries in Training》在AAAI2023上发表，Oral paper（CCF-A）。</td>
										</tr>

										<tr>
											<td><b>2022/10:</b></td>
											<td>荣获硕士研究生国家奖学金。</td>
										</tr>

										<!-- <tr>
											<td><b>2022.10:</b></td>
											<td>荣获天津大学研究生学业一等奖学金！</td>
										</tr>

										<tr>
											<td><b>Aug 2022:</b></td>
											<td>我将在卫津路校区开始我的硕士三年级生活！</td>
										</tr>

										<tr>
											<td><b>Jun 2022:</b></td>
											<td>参加并完成<a href="https://course.itxueyuan.com/198" target="_blank">英特尔® OpenVINO™工具套件初级课程</a>,并获得“Introduction to Intel® Distribution of openVINO™ toolkit for Computer Vision Applications”证书！</td>
										</tr>

										<tr>
											<td><b>Jun 2022:</b></td>
											<td>参加并完成吴恩达老师的<a href="https://www.coursera.org/learn/machine-learning" target="_blank">Machine Learning (New Version)</a>课程,并获得合格证书！</td>
										</tr>

										<tr>
											<td><b>May 2022:</b></td>
											<td>参加并完成吴恩达老师的<a href="https://www.coursera.org/learn/neural-networks-deep-learning" target="_blank">Deep Learning</a>课程,并获得合格证书！</td>
										</tr>

										<tr>
											<td><b>Mar 2022:</b></td>
											<td>在<a href="https://www.icourse163.org/" target="_blank">MOOC</a>上参加并完成温州大学黄海广老师的<a href="https://www.icourse163.org/course/WZU-1464096179?tid=1466943454" target="_blank">机器学习</a>课程,并获得合格证书！</td>
										</tr>

										<tr>
											<td><b>Mar 2022:</b></td>
											<td>第二次参加并完成吴恩达老师的<a href="https://www.coursera.org/learn/machine-learning" target="_blank">Machine Learning (Old Version)</a>课程,并获得合格证书！</td>
										</tr>

										<tr>
											<td><b>Feb 2022:</b></td>
											<td>在<a href="https://www.icourse163.org/" target="_blank">MOOC</a>上参加并完成北京理工大学嵩天老师的<a href="https://www.icourse163.org/course/BIT-268001?tid=1465711517" target="_blank">Python语言程序设计</a>课程,并获得合格证书！</td>
										</tr>

										<tr>
											<td><b>Jan 2022:</b></td>
											<td>在天津市津南区参加<a href="picture/巾帼微课堂.jpg" target="_blank">“巾帼微课堂”活动</a>!</a></td>
										</tr>

										<tr>
											<td><b>Oct 2021:</b></td>
											<td>荣获中国石油奖学金，全校共10人!</td>
										</tr>

										<tr>
											<td><b>Oct 2021:</b></td>
											<td>荣获天津大学研究生学业一等奖学金！</td>
										</tr>

										<tr>
											<td><b>Oct 2021:</b></td>
											<td>荣获天津大学三好学生！</td>
										</tr>

										<tr>
											<td><b>Aug 2021:</b></td>
											<td>参加<a href="http://cvit.iiit.ac.in/summerschool2021/program.php" target="_blank">第五届CVIT IIIT暑期学校</a>的TensorFlow实践培训！</td>
										</tr>

										<tr>
											<td><b>Jul 2021:</b></td>
											<td>参加<a href="picture/全国大数据与人工智能大会.jpg" target="_blank">全国大数据与人工智能大会（CSIAM-BDAI 2021）</a>!</a></td>
										</tr>

										<tr>
											<td><b>Nov 2020:</b></td>
											<td>参加第十七届“华为杯”中国研究生数学建模竞赛，获得国家级二等奖！</td>
										</tr>

										<tr>
											<td><b>Oct 2020:</b></td>
											<td>荣获天津大学研究生学业一等奖学金！</td>
										</tr>

										<tr>
											<td><b>Seq 2020:</b></td>
											<td>将前往<a href="http://www.tju.edu.cn/" target="_blank">天津大学</a>，数学学院，应用数学中心（13个国家应用数学中心之一），数学专业，攻读硕士学位，师从<a class="tag" href="http://faculty.tju.edu.cn/176110/zh_CN/index.htm" target="_blank"><strong><font color="#ff6666">吴偶</font></strong></a>教授！</td>
										</tr>

										<tr>
											<td><b>Jul 2020:</b></td>
											<td>在<a class="tag" href="https://www.qcc.com/firm/c29a35cf174b43d03fd4263513bf193c.html" target="_blank">青岛学大教育培训中心</a>兼职，职位是高中数学教师！</td>
										</tr>

										<tr>
											<td><b>Jun 2020:</b></td>
											<td>毕业于<a href="https://www.tiangong.edu.cn/" target="_blank">天津工业大学</a>，获得信息与计算科学专业 理学学士学位！</td>
										</tr>

										<tr>
											<td><b>Jun 2020:</b></td>
											<td>被评为天津工业大学优秀毕业生！</td>
										</tr>

										<tr>
											<td><b>Dec 2019:</b></td>
											<td>荣获天津工业大学“十佳大学生”称号！</td>
										</tr>

										<tr>
											<td><b>Nov 2019:</b></td>
											<td>荣获国家奖学金！</td>
										</tr>

										<tr>
											<td><b>Oct 2019:</b></td>
											<td>荣获天津市大学生创新奖学金！</td>
										</tr>

										<tr>
											<td><b>Oct 2018:</b></td>
											<td>荣获国家励志奖学金！</td>
										</tr>

										<tr>
											<td><b>Nov 2017:</b></td>
											<td>在天津市张家窝镇参加<a href="picture/志愿者活动.jpg" target="_blank">社区志愿者活动</a>!</a></td>
										</tr>

										<tr>
											<td><b>Nov 2017:</b></td>
											<td>荣获全国大学生数学建模竞赛 天津市一等奖！</td>
										</tr>

										<tr>
											<td><b>Jul 2017:</b></td>
											<td>参加为期两个月的数学建模“魔鬼训练”，期间得到了汪晓银老师的鼎力支持，得到了胡坤学长的极大帮助！</td>
										</tr> -->
									</table>
								</div>
							</ol>

				<h2>教育经历</h2>
					<p>
<!--					  &emsp;2023/09-&nbsp;&nbsp;&nbsp;至今&emsp;&nbsp;|&nbsp;&nbsp;<font color="#ff6666">北京大学</font>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;电子信息专业&emsp;&nbsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;-<br>-->
					  &emsp;2023/09&nbsp;-&nbsp;&nbsp;至今&emsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">国家软件工程研究中心，&emsp;北京大学</font>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;电子信息&emsp;&nbsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<br>
					  &emsp;2020/09&nbsp;-&nbsp;2023/06&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">天津市国家应用数学中心，天津大学 (导师：吴偶教授)</font>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数学&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<br>
					  <!-- &emsp;2016/09-2020/06&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">天津工业大学</font>&nbsp;&nbsp;&nbsp;信息与计算科学专业&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;获理学学士学位<br>
					  &emsp;2013/09-2016/06&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">青岛市</font>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;胶州市实验中学&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;高中<br> -->
					</p>










        <div id = "publications"><h2>出版物</h2></div>
        <ol>

            <li id="xiao2023com" class="entry">
                <strong><font color="#0071BF">Combining Adversaries with Anti-adversaries in Training</font></strong>,
                <strong><font color="#ff6666"> AAAI</font></strong>, 2023, <strong><font color="#9045DC"> CCF Rank A, Full Paper (oral)</font></strong>.
                <a href="javascript:toggleInfo('xiao2023com','bibtex')">[BibTeX]</a><a href="https://arxiv.org/abs/2304.12550">[PDF]</a>
                <a href="javascript:toggleInfo('xiao2023coms','abstract')">[Abstract]</a>
            <div class="author"><strong>Xiaoling Zhou</strong>, Nan Yang, and Ou Wu*.</div>

            </li>
            <div id="bib_xiao2023com" class="bibtex noshow">
            <b>BibTeX</b>:
            <pre>
            @inproceedings{xiao2023com,
              author = {Xiaoling Zhou, Nan Yang, and Ou Wu.},
              title = {Combining Adversaries with Anti-adversaries in Training},
              booktitle = {AAAI 2023},
              year = {2023},
              pages = {1--8},
              url = {arXiv preprint arXiv:XXX}
            }
            </pre>
            </div>
            <div id="abs_xiao2023coms" style="text-align:justify; text-justify:inter-ideograph;" class="abstract noshow" >
                <b>Abstract</b>: Adversarial training is an effective learning technique to improve the robustness of deep neural networks. In this study, the influence of adversarial training on deep learning models in terms of fairness, robustness, and generalization is
                theoretically investigated under more general perturbation scope that different samples can have different perturbation directions (the adversarial and anti-adversarial directions) and varied perturbation bounds. Our theoretical explorations suggest that
                the combination of adversaries and anti-adversaries (samples with anti-adversarial perturbations) in training can be more effective in achieving better fairness between classes and a better tradeoff between robustness and generalization in some typical
                learning scenarios (e.g., noisy label learning and imbalance learning) compared with standard adversarial training. On the basis of our theoretical findings, a more general learning objective that combines adversaries and antiadversaries with varied bounds
                on each training sample is presented. Meta learning is utilized to optimize the combination weights. Experiments on benchmark datasets under different learning scenarios verify our theoretical findings and the effectiveness of the proposed methodology.
            </div>



            <li id="zhou2022which" class="entry">
                <strong><font color="#0071BF">Which Samples Should Be Learned First, Easy or Hard?</font></strong>,
                <strong><font color="#ff6666"> TNNLS</font></strong>, 2023, <strong><font color="#9045DC"> CCF Rank B (SCI Q1), IF:10.4</font></strong>.
                <a href="javascript:toggleInfo('zhou2022which','bibtex')">[BibTeX]</a><a href="https://ieeexplore.ieee.org/document/10155763">[PDF]</a>
                <a href="javascript:toggleInfo('zhou2022whichs','abstract')">[Abstract]</a>
            <div class="author"><strong>Xiaoling Zhou</strong>, and Ou Wu*.</div>
            </li>
            <div id="bib_zhou2022which" class="bibtex noshow">
            <b>BibTeX</b>:
            <pre>
                @article{zhou2023samples,
                    title={Which Samples Should Be Learned First: Easy or Hard?},
                    author={Zhou, Xiaoling and Wu, Ou},
                    journal={IEEE Transactions on Neural Networks and Learning Systems},
                    year={2023},
                    publisher={IEEE}
                  }
            </pre>

            </div>

            <div id="abs_zhou2022whichs" style="text-align:justify; text-justify:inter-ideograph;" class="abstract noshow">
                <b>Abstract</b>: An effective weighting scheme for training samples is essential for learning tasks. Numerous weighting schemes have been proposed. Some schemes take the easy-first mode, whereas some others take the hard-first one. Naturally, an interesting yet realistic question is
                raised. Which samples should be learned first given a new learning task, easy or hard? To answer this question, both theoretical analyses and experimental verification are conducted. First, a general optimized objective function is proposed, revealing the relationship between the difficulty
                distribution and the difficulty-based sample weights. Second, on the basis of the optimized objective function, theoretical answers are obtained. Besides the easy-first and hard-first modes, there are two other priority modes, namely, medium-first and two-endsfirst. The prior mode does not
                necessarily remain unchanged during the training process. Third, an effective and universal solution is proposed to select the optimal priority mode when there is no prior knowledge or theoretical clues. The four modes, namely, easy/medium/hard/two-ends-first, can be flexibly switched in the
                proposed solution. Fourth, a wide range of experiments is conducted under various scenarios to further compare the weighting schemes in different modes. On the basis of these works, reasonable and comprehensive answers are obtained. Factors including the distribution of samples’ learning
                difficulties and the validation data determine which samples should be learned first in a learning task.
            </div>


            <li id="implicit" class="entry">
                <strong><font color="#0071BF">Implicit Counterfactual Data Augmentation for Deep Neural Networks</font></strong>,
                <strong><font color="#ff6666"> arXiv</font></strong>, 2023.
                <a href="javascript:toggleInfo('implicit','bibtex')">[BibTeX]</a><a href="https://arxiv.org/abs/2304.13431">[PDF]</a>
                <a href="javascript:toggleInfo('implicit1','abstract')">[Abstract]</a>
            <div class="author"><strong>Xiaoling Zhou</strong> and Ou Wu*.</div>

            </li>
            <div id="implicit" class="bibtex noshow">
            <b>BibTeX</b>:
            <pre>
                @article{zhou2023implicit,
                    title={Implicit Counterfactual Data Augmentation for Deep Neural Networks},
                    author={Zhou, Xiaoling and Wu, Ou},
                    journal={arXiv preprint arXiv:2304.13431},
                    year={2023}
                  }
            </pre>
            </div>
            <div id="implicit1" style="text-align:justify; text-justify:inter-ideograph;" class="abstract noshow" >
                <b>Abstract</b>: Machine-learning models are prone to capturing the spurious correlations between non-causal attributes and classes, with counterfactual data augmentation being a promising direction for breaking these spurious associations. However, explicitly generating counterfactual data is challenging, with the training efficiency declining. Therefore, this study proposes an implicit counterfactual data augmentation (ICDA) method to remove spurious correlations and make stable predictions. Specifically, first, a novel sample-wise augmentation strategy is developed that generates semantically and counterfactually meaningful deep features with distinct augmentation strength for each sample. Second, we derive an easy-to-compute surrogate loss on the augmented feature set when the number of augmented samples becomes infinite. Third, two concrete schemes are proposed, including direct quantification and meta-learning, to derive the key parameters for the robust loss. In addition, ICDA is explained from a regularization aspect, with extensive experiments indicating that our method consistently improves the generalization performance of popular depth networks on multiple typical learning scenarios that require out-of-distribution generalization.
            </div>


            <li id="xiao2022under" class="entry">
                <strong><font color="#0071BF">Understanding Difficulty-Based Sample Weighting in Deep Learning</font></strong>,
                <strong><font color="#ff6666"> ECML-PKDD</font></strong>, 2022, <strong><font color="#9045DC"> CCF Rank B, Full Paper (oral)</font></strong>.
                <a href="javascript:toggleInfo('xiao2022under','bibtex')">[BibTeX]</a><a href="https://arxiv.org/abs/2301.04850">[PDF]</a>
                <a href="javascript:toggleInfo('xiao2022unders','abstract')">[Abstract]</a>
            <div class="author"><strong>Xiaoling Zhou</strong>, Ou Wu*, Weiyao Zhu, and Ziyang Liang.</div>

            </li>
            <div id="bib_xiao2022under" class="bibtex noshow">
            <b>BibTeX</b>:
            <pre>
            @inproceedings{xiao2022under,
              author = {Xiaoling Zhou, Ou Wu, Weiyao Zhu, and Ziyang Liang.},
              title = {Understanding Difficulty-Based Sample Weighting in Deep Learning},
              booktitle = {ECML-PKDD 2022},
              year = {2022},
              pages = {1--16},
              url = {https://arxiv.org/pdf/2301.04850.pdf},
            }
            </pre>
            </div>
            <div id="abs_xiao2022unders" style="text-align:justify; text-justify:inter-ideograph;" class="abstract noshow" >
                <b>Abstract</b>: Sample weighting is widely used in deep learning. A large number of weighting methods essentially utilize the learning difficulty of a training sample to calculate its weight. In this study, this scheme is called difficulty-based weighting. Two important issues
                arise when explaining this scheme. First, a universal difficulty measure that can be theoretically guaranteed for training samples does not exist. The learning difficulties of the samples are determined by multiple factors, including noise level, imbalance degree, margin, and
                uncertainty. Nevertheless, existing measures only consider a single factor or in part, but not in their entirety. Second, a comprehensive theoretical explanation is lacking with respect to demonstrating why difficulty-based weighting schemes are effective in deep learning. In
                this study, we theoretically prove that the generalization error of a sample can be used as a universal difficulty measure. Furthermore, we provide formal theoretical justifications on the role of difficulty-based weighting for deep learning, consequently revealing its positive
                influences on both the optimization dynamics and generalization performance of deep models, which is instructive to a number of weighting schemes under active research.
            </div>






            <li id="xiao2021drop" class="entry">
                <strong><font color="#0071BF">Drop "Noise" Edge: An Approximation of the Bayesian GNNs</font></strong>,
                <strong><font color="#ff6666"> ACPR</font></strong>, 2022.
                <a href="javascript:toggleInfo('xiao2021drop','bibtex')">[BibTeX]</a><a href="https://dl.acm.org/doi/10.1007/978-3-031-02444-3_5">[PDF]</a>
                <a href="javascript:toggleInfo('xiao2021drops','abstract')">[Abstract]</a>
            <div class="author"><strong>Xiaoling Zhou</strong>, and Ou Wu*.</div>

            </li>
            <div id="bib_xiao2021drop" class="bibtex noshow">
            <b>BibTeX</b>:
            <pre>
            @inproceedings{xiao2021drop,
              author = {Xiaoling Zhou, and Ou Wu.},
              title = {Drop "Noise" Edge: An Approximation of the Bayesian GNNs},
              booktitle = {Proceedings of the 6th Asian Conference on Pattern Recognition (ACPR 2021)},
              year = {2021},
              pages = {59--72},
              url = {https://dx.doi.org/10.1007/978-3-031-02444-3_5}
            }
            </pre>
            </div>
            <div id="abs_xiao2021drops" style="text-align:justify; text-justify:inter-ideograph;" class="abstract noshow" >
                <b>Abstract</b>: Graph neural networks (GNNs) have proven to be powerful tools for graph analysis. The key idea is to recursively propagate and gather information along the edges of a given graph. Although they have been successful, they are still limited by over-smoothing and noise in
                the graph. Over-smoothing means that the representation of each node will converge to the similar value as the number of layers increases. "Noise" edges refer to edges with no positive effect on graph representation in this study. To solve the above problems, we propose DropNEdge (Drop
                "Noise" Edge), which filters useless edges based on two indicators, namely, feature gain and signal-to-noise ratio. DropNEdge can alleviate over-smoothing and remove "noise" edges in the graph effectively. It does not require any changes to the network's structure, and it is widely adapted
                to various GNNs. We also show that the use of DropNEdge in GNNs can be interpreted as an approximation of the Bayesian GNNs. Thus, the models' uncertainty can be obtained.
            </div>


            <li id="Zhou2022in" class="entry">
                <strong><font color="#0071BF">Increasing Naturalness of Human-machine Dialogue: the Users’ Choices Inference of Options in Machine-raised Questions</font></strong>,
                 <strong><font color="#ff6666">Knowledge-based Systems</font></strong>, Vol. 243(108485), pp. 1-13, 2022, <strong><font color="#9045DC"> CCF Rank C (SCI Q1), IF:8.038</font></strong>.
                <a href="javascript:toggleInfo('Zhou2022in','bibtex')">[BibTeX]</a><a href="https://dl.acm.org/doi/abs/10.1016/j.knosys.2022.108485">[PDF]</a>
                <a href="javascript:toggleInfo('Zhou2022ins','abstract')">[Abstract]</a>

                <div class="author"><strong>Xiaoling Zhou</strong>, Ou Wu*, and Chao Jiang.</div>

            </li>
            <div id="bib_Zhou2022in" class="bibtex noshow">
            <b>BibTeX</b>:
            <pre>
            @article{Zhou2022in,
              author = {Xiaoling Zhou, Ou Wu, and Chao Jiang.},
              title = {Increasing Naturalness of Human-machine Dialogue: the Users’ Choices Inference of Options in Machine-raised Questions},
              journal = {Knowledge-based Systems},
              year = {2022},
              volume = {243},
              number = {108485},
              pages = {1--13},
              url = {https://doi.org/10.1016/j.knosys.2022.108485},
              doi = {https://doi.org/10.1016/j.knosys.2022.108485}
            }
            </pre>
            </div>
            <div id="abs_Zhou2022ins" style="text-align:justify; text-justify:inter-ideograph;" class="abstract noshow">
                <b>Abstract</b>:In many practical applications, the machine needs to actively ask humans to obtain their intents. The process that the machine raises questions and users return answers is called reverse QA, which is an important part of a human–machine dialogue.
                However, in many dialogue systems, the machine restricts users from answering questions by clicking on option items, which is unnatural and restricted. In addition, this method may lose important information expressed by users. Users should be allowed to answer
                questions in natural language in a more natural and intelligent dialogue system. To obtain users’ intents, users’ choices of questions’ options must be inferred from their answers. In this paper, we propose an advanced answer understanding network (UCINet) which
                infers users’ choices of options in machine-raised questions accurately and efficiently according to the users’ answer. Furthermore, metric learning is introduced for the model to learn better text representations. Based on the assumption that texts are determined
                by both semantics and styles, we propose a stylebased answer generation network (SAGNet) which can generate various answers with different styles for a question. The generated answers are used to achieve data augmentation for UCINet’s training. Experimental results
                on two reverse QA data sets demonstrate that UCINet achieves impressive results compared to other strong competitors. Using SAGNet for answer generation, we obtain answers with various styles and good quality. Our work can be widely used in intelligent customer
                service, mobile phone assistants, and other human–machine dialogue systems.
            </div>







            <li id="rui2020" class="entry">
                <strong><font color="#0071BF">Inter-subdiscipline Analysis Based on Mathematical Statements</font></strong>,
                <strong><font color="#ff6666"> JCDL'20</font></strong>, 2020.
                <a href="javascript:toggleInfo('rui2020','bibtex')">[BibTeX]</a><a href="https://dl.acm.org/doi/abs/10.1145/3383583.3398574">[PDF]</a>
                <a href="javascript:toggleInfo('rui2020s','abstract')">[Abstract]</a>
            <div class="author">Rui Wang, <strong>Xiaoling Zhou</strong>, Jian Wu, and Ou Wu*.</div>
            </li>
            <div id="bib_rui2020" class="bibtex noshow">
            <b>BibTeX</b>:
            <pre>
            @inproceedings{rui2020,
              author = {Rui Wang, Xiaoling Zhou, Jian Wu, and Ou Wu.},
              title = {Inter-subdiscipline Analysis Based on Mathematical Statements},
              booktitle = {Proceedings of the ACM/IEEE Joint Conference on Digital Libraries in 2020 (JCDL'20)},
              year = {2020},
              pages = {483--484},
              url = {https://doi.org/10.1145/3383583.3398574}
            }
            </pre>
            </div>

            <div id="abs_rui2020s" style="text-align:justify; text-justify:inter-ideograph;" class="abstract noshow">
                <b>Abstract</b>: A mathematical paper contains various mathematical statements, including definitions, theorems, lemmas, and so on. The mining of mathematical literature currently focuses on formulas and disregards statements. The present study investigates the (automatic) subdiscipline
                classification for mathematical statements. The classification results are applied into inter-subdiscipline analysis, including proportion and dependency analyses. First, a statement learning data is directly compiled from mathematical textbooks with a little human labeling to train an
                effective subdiscipline classifier. Second, a relatively large corpus, namely, analysis data, is compiled from mathematical journals. The classification results on the analysis data are subsequently used to quantify the intersubdisciplinary relationships and conduct proportion analysis.
                Lastly, the dependency of different subdisciplines is analyzed and dependency chains among subdisciplines can be obtained.
            </div>



            <!-- <li id="zhou2019" class="entry">
                <strong><font color="#0071BF">基于效率最大化的RGV动态调度的算法设计与程序验证</font></strong>,
                <strong><font color="#ff6666"> 中小企业管理与科技</font></strong>, Vol. 2(1), pp. 1-2, 2019.
                <a href="javascript:toggleInfo('zhou2019','bibtex')">[BibTeX]</a><a href="./pdf/zhou-2019.pdf">[PDF]</a>
                <a href="javascript:toggleInfo('zhou2019s','abstract')">[Abstract]</a>
            <div class="author"><strong>周晓玲*</strong>, 李政, 李慧东, 张卓力, 过昱企.</div>
            </li>
            <div id="bib_zhou2019" class="bibtex noshow">
            <b>BibTeX</b>:
            <pre>
            @article{zhou2019,
              author = {周晓玲, 李政, 李慧东, 张卓力, 过昱企.},
              title = {基于效率最大化的RGV动态调度的算法设计与程序验证},
              journal = {中小企业管理与科技},
              year = {2019},
              volume = {2},
              number = {1},
              pages = {1--2},
              url = {https://kns.cnki.net/kcms2/article/abstract?v=3uoqIhG8C44YLTlOAiTRKibYlV5Vjs7iLik5jEcCI09uHa3oBxtWoLsuiTCUcLAWS5shsd7Sr1wVqJuljXXbGnEnUSmw0ZP5&uniplatform=NZKPT}
            }
            </pre>
            </div>

            <div id="abs_zhou2019s" style="text-align:justify; text-justify:inter-ideograph;" class="abstract noshow">
                <b>Abstract</b>: 论文旨在研究智能RGV（轨道式导引小车）的动态调度策略，针对具体加工过程中的不同情况分别建立以效率最大化为目标的多目标优化模型和实时动态调度策略模型。针对加工情况为两道工序且可能存在故障的情况建立动态调度规则，运用MATLAB软件对动态调度模型进行求解，得到最优调度方案。利用组内检验和组间检验对模型的实用性和算法的有效性进行
                了检验并评价了模型的优缺点。最后，针对RGA可提前预测CNC完成情况方面对模型进行了合理有效展望。
            </div> -->


        <li>
            <strong><font color="#0071BF">一种可解释性的深度学习样本赋权方法</font></strong>,<strong><font color="#ff6666">发明专利</font></strong>.
            公开号：CN115730651A, 2022.
            <div class="author">吴偶, <strong>周晓玲</strong>.</div>
        </li>

        <li>
            <strong><font color="#0071BF">一种用于实验室的计算机通信设备</font></strong>,<strong><font color="#ff6666">实用新型专利</font></strong>,
             专利号：ZL 2019 2 0113518.4, 2019.
            <div class="author">李政, <strong>周晓玲</strong>, 过昱企, 张卓力, 甘伟荣.</div>
        </li>

        <li>
            <strong><font color="#0071BF">“爱骑”软件 V1.0</font></strong>,<strong><font color="#ff6666">软件著作权</font></strong>,
             登记号：2019SR0533606, 2019.
            <div class="author"><strong>周晓玲</strong>, 王雪娜, 李政斌, 李竣玺, 翟巧灵, 过昱企.</div>
        </li>
        </ol>





				<div id = "awards"><h2>所获奖项</h2></div>
					<ol>
						<li>2020/12&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">第十七届“华为杯”中国研究生数学建模竞赛</font>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;国家级 二等奖<br></li>
						<li>2019/09&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">第十五届挑战杯天津市大学生课外学术科技作品竞赛</font>&emsp;&emsp;&emsp;&emsp;&emsp;天津市 三等奖<br></li>
						<!-- <li>2019/05&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">天津工业大学第十三届学生课外学术科技作品竞赛</font>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;院校级 二等奖<br></li> -->
						<li>2019/04&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">美国大学生数学建模竞赛</font>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;国际级 一等奖 (M奖)<br></li>
						<li>2018/11&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">全国大学生数学竞赛 (天津赛区)</font>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;天津市 二等奖<br></li>
						<!-- <li>2018/07&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">天津工业大学“创新杯”数学建模竞赛</font>&nbsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;院校级 一等奖<br></li> -->
						<li>2018/06&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">天津市大学生物理竞赛</font>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;&nbsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;天津市 特等奖<br></li>
						<li>2018/05&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">Mathorcup全球大学生数学建模挑战赛</font>&nbsp;&nbsp;&nbsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;国家级 特等奖<br></li>
					    <li>2018/05&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">全国大学生英语竞赛</font>&nbsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&emsp;&emsp;&nbsp;国家级 一等奖<br></li>
					    <li>2018/04&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">美国大学生数学建模竞赛</font>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;&nbsp;国际级 二等奖 (H奖)<br></li>
					    <li>2018/06&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">“泰迪杯”全国数据挖掘挑战赛</font>&nbsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;&nbsp;国家级 三等奖<br></li>
					    <li>2017/11&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">全国大学生数学建模竞赛</font>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;&nbsp;天津市 一等奖<br></li>
					    <li>2017/11&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">全国大学生数学竞赛 (天津赛区)</font>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;&nbsp;天津市 三等奖<br></li>
					    <!-- <li>2017/07&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">天津工业大学“求实杯”数学竞赛</font>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;院校级 二等奖<br></li>
						<li>2017/07&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">天津工业大学“兴华杯”英语竞赛</font>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;院校级 二等奖<br></li> -->
					    <li>2017/05&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">全国大学生英语竞赛</font>&nbsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&emsp;&emsp;&nbsp;国家级 二等奖<br></li>

					</ol>


				<div id = "honors"><h2>所获荣誉</h2></div>
					<ol>
					<li>2023/06&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">天津大学优秀毕业生</font><br></li>
					<li>2023/06&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">天津大学优秀硕士学位论文</font><br></li>
					  <li>2022/10&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">研究生国家奖学金</font><br></li>
					  <li>2022/10&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">天津大学优秀学生干部</font><br></li>
					  <!-- <li>2022/09&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">天津大学研究生学业一等奖学金</font><br></li> -->
					  <li>2021/10&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">中国石油奖学金</font><br></li>
					  <li>2021/09&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">天津大学研究生学业一等奖学金</font><br></li>
					  <li>2021/09&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">天津大学三好学生</font><br></li>
					  <!-- <li>2021/09&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">天津大学研究生学业一等奖学金</font><br></li>
					  <li>2020/09&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">天津大学研究生学业一等奖学金</font><br></li> -->
					  <li>2020/06&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">天津工业大学优秀毕业生</font><br></li>
					  <!-- <li>2020/06&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">天津工业大学先锋学子宣讲团成员 (全校22000多名学生 (本、硕、博)，仅50人)</font><br></li> -->
					  <li>2020/05&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">入选 2020年本专科生国家奖学金获奖学生代表名录 (人民日报)</font><br></li>
					  <li>2019/12&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">天津市大学生创新创业奖学金</font><br></li>
					  <!-- <li>2019/11&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">天津工业大学第二届十佳大学生 (全校22000多名学生 (本、硕、博)，仅有10人)</font><br></li> -->
					  <li>2019/10&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">本科生国家奖学金</font><br></li>
					  <!-- <li>2019/10&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">天津工业大学校长一等奖学金</font><br></li> -->
					  <!-- <li>2019/10&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">天津工业大学三好学生</font><br></li> -->
					  <li>2019/09&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">天津工业大学数学英才奖</font><br></li>
					  <li>2018/12&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">天津工业大学三好学生</font><br></li>
					  <!-- <li>2018/11&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">国家励志奖学金</font><br></li> -->
					  <li>2018/10&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">天津工业大学校长一等奖学金</font><br></li>
					  <!-- <li>2017/12&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">天津工业大学三好学生</font><br></li> -->
					  <li>2017/11&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">国家励志奖学金</font><br></li>
					  <!-- <li>2017/10&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">天津工业大学校长一等奖学金</font><br></li> -->
					</ol>





					<!-- <h2>博士研究生阶段</h2>
						<p  style="margin-left:3em;" > <strong>-</strong>：-</p> -->

<!--					<p  style="margin-left:3em;" > <strong>国家自然科学基金</strong>： &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;文献理解驱动的深度元学习研究&nbsp;&nbsp;&nbsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;|&nbsp;&emsp;&emsp;项目第三参与人</p>-->
<!--                    <p  style="margin-left:3em;" > <strong>天津自然基金重点项目</strong>： &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;互联网大规模用户文本内容的挖掘&nbsp;&nbsp;&nbsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;|&nbsp;&emsp;&emsp;项目第三参与人</p>-->
<!--                    <p  style="margin-left:3em;" > <strong>天津大学应用数学中心重点</strong>： &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;人工智能中的组合数学方法&nbsp;&nbsp;&nbsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;|&nbsp;&emsp;&emsp;项目参与人</p>-->
<!--                    <p  style="margin-left:3em;" > <strong>企业横向项目</strong>： &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;工业电路图的智能识别&nbsp;&nbsp;&nbsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;|&nbsp;&emsp;&emsp;项目第二参与人</p>-->

					<div id = "projects"><h2>科研项目</h2></div>
						<p  style="margin-left:3em;" > <strong>国家自然科学基金项目</strong>： &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;文献理解驱动的深度元学习研究</p>
						<p  style="margin-left:3em;" > <strong>天津自然基金重点项目</strong>： &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;互联网大规模用户文本内容的挖掘</p>
						<p  style="margin-left:3em;" > <strong>天津大学应用数学中心重点项目</strong>： &emsp;&emsp;&emsp;人工智能中的组合数学方法</p>
						<p  style="margin-left:3em;" > <strong>企业横向项目</strong>： &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;工业电路图的智能识别</p>

					<!-- <h2>本科生阶段</h2> -->
						<p  style="margin-left:3em;" > <strong>国家级大学生创新创业项目</strong>： &emsp;&emsp;&emsp;&emsp;&emsp;爱骑 app的开发和绿色自行车的推广 <font color="#bf6666">(主持)</font></p>
						<p  style="margin-left:3em;" > <strong>校级师生合作科研项目</strong>： &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;非线性基因调控网络的可达集估计及其反馈控制研究</p>
						<p  style="margin-left:3em;" > <strong>校级大学生创新创业项目</strong>： &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;基于互联网+的养老服务平台</p>







				<div id = "acs"><h2>学术服务</h2></div>
					<p>
					审稿人: TIP, Journal of Supercomputing.<br>
					</p>















				<!-- <h2>工作经历</h2>
					<p>
					2020/04-2020/09&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">天津北棠科技有限公司</font>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;实习&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;算法工程师<br>
					2019/07-2019/08&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">青岛学大教育培训中心</font>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;实习&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;兼职高中数学老师<br>
					</p>
				</div> -->

				<!-- <div class="feature">
				<h2>技能证书</h2>
					<ol>
						<li>2020/11&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">计算机二级</font>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;Python语言程序设计<br></li>
						<li>2020/05&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">普通话考试</font>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;二级甲等证书<br></li>
						<li>2018/03&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">计算机二级</font>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;MS office高级应用<br></li>
						<li>2017/09&nbsp;&nbsp;|&nbsp;&nbsp;<font color="#bf6666">计算机二级</font>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;C语言程序设计<br></li>
					</ol> -->


				<!-- <h2>所学课程</h2>
					<p>机器学习、数据分析与数据挖掘、计算机组成原理、随机过程、人工智能基础、最优化理论与方法、几何与拓扑。</p> -->

				<!-- <h2>兴趣爱好</h2> -->
					<!-- <p>
					<b><strong><font color="#ff6666">爱好：</font></strong></b>阅读、跑步、心理学<br>
					</p>

				<h2>未来展望</h2>
					<p>
					<b>勤于思考，善于总结</b><br>
                    <b>日拱一卒，功不唐捐</b><br>
					<b><strong><font color="#ff6666">Write the code, Change the world.</font></strong></b><br>
					</p> -->
				<!-- <h2>Contact with me</h2>
					<p><b><strong><font color="#ff6666">Email：</font></strong></b>xiaolingzhou@tju.edu.cn</p> -->

					
				
				</div>

			</div><!-- end of content-->
		</div><!-- end of pagecell1-->
	</body>
</html>
